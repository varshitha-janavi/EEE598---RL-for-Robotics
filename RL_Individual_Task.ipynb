{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DqxFC13Mxte",
        "outputId": "061e740e-8082-4313-e19b-bfff0e16c29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values:\n",
            "[[ 0.6206    0.734     0.86      1.      ]\n",
            " [ 0.51854   0.        0.734    -1.      ]\n",
            " [ 0.426686  0.51854   0.6206    0.51854 ]]\n",
            "Policy:\n",
            "['right' 'right' 'right' '+1']\n",
            "['up' 'Wall' 'up' '-1']\n",
            "['up' 'right' 'up' 'left']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Grid and Rewards\n",
        "rows, cols = 3, 4\n",
        "rewards = np.full((rows, cols), -0.04)\n",
        "rewards[0, 3] = 1\n",
        "rewards[1, 3] = -1\n",
        "\n",
        "#Wall and Terminal States\n",
        "wall = (1, 1)\n",
        "terminals = [(0, 3), (1, 3)]\n",
        "\n",
        "#Initialize Value Function\n",
        "values = np.zeros((rows, cols))\n",
        "values[0, 3] = 1\n",
        "values[1, 3] = -1\n",
        "\n",
        "#Initial Policy\n",
        "policy = np.array([\n",
        "    ['up', 'right', 'right', 'down'],\n",
        "    ['up', None, 'down', 'down'],\n",
        "    ['left', 'left', 'up', 'left']\n",
        "])\n",
        "\n",
        "#Actions and Discount Factor\n",
        "actions = ['up', 'down', 'left', 'right']\n",
        "gamma = 0.9\n",
        "\n",
        "#Move Function for each action\n",
        "def move(r, c, action):\n",
        "    if action == 'up' and r > 0:\n",
        "        return r - 1, c\n",
        "    if action == 'down' and r < rows - 1:\n",
        "        return r + 1, c\n",
        "    if action == 'left' and c > 0:\n",
        "        return r, c - 1\n",
        "    if action == 'right' and c < cols - 1:\n",
        "        return r, c + 1\n",
        "    return r, c\n",
        "\n",
        "#Evaluate and Improve Policy\n",
        "def evaluate_and_improve_policy(policy, values):\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for r in range(rows):\n",
        "            for c in range(cols):\n",
        "                #Skip Wall and Terminal States\n",
        "                if (r, c) in terminals or (r, c) == wall:\n",
        "                    continue\n",
        "\n",
        "                #Policy Evaluation\n",
        "                v = values[r, c]  #Current Value of State\n",
        "                next_r, next_c = move(r, c, policy[r, c])  #Finding Next State\n",
        "                values[r, c] = rewards[r, c] + gamma * values[next_r, next_c]  #Update based on Bellman Equation\n",
        "                delta = max(delta, abs(v - values[r, c]))\n",
        "        if delta < 1e-6: #Convergence Criterion - if delta(change) is small enough, stop iterations)\n",
        "            break\n",
        "\n",
        "    #Policy Improvement\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            if (r, c) in terminals or (r, c) == wall:\n",
        "                continue\n",
        "            best_action = None\n",
        "            best_value = float('-inf')  #Initially choose very small value\n",
        "\n",
        "            #Choose the action with the highest value\n",
        "            for action in actions:\n",
        "                next_r, next_c = move(r, c, action)  #Find next state for current action\n",
        "                v = rewards[r, c] + gamma * values[next_r, next_c]  #Calculate value for this action\n",
        "\n",
        "                #If this action is better than the previous, update\n",
        "                if v > best_value:\n",
        "                    best_value = v\n",
        "                    best_action = action\n",
        "            policy[r, c] = best_action #Update Policy\n",
        "\n",
        "    policy[wall] = \"Wall\"\n",
        "    policy[0, 3] = \"+1\"\n",
        "    policy[1, 3] = \"-1\"\n",
        "\n",
        "for _ in range(10):\n",
        "    evaluate_and_improve_policy(policy, values)\n",
        "\n",
        "#Print Final Results\n",
        "print(\"Values:\")\n",
        "print(values)\n",
        "\n",
        "print(\"Policy:\")\n",
        "for row in policy:\n",
        "    print(row)"
      ]
    }
  ]
}